import asyncio
import os
import json
from dotenv import load_dotenv
from openai import AsyncOpenAI
from mcp import ClientSession
from mcp.client.sse import sse_client


# 1. ‡πÇ‡∏´‡∏•‡∏î Config ‡∏à‡∏≤‡∏Å .env
load_dotenv()
API_KEY = os.getenv("LLM_API_KEY")
BASE_URL = os.getenv("LLM_BASE_URL")
MODEL_NAME = os.getenv("LLM_MODEL", "gpt-4o-mini")
SERVER_URL = "http://localhost:8000/sse"

# ‡∏™‡∏£‡πâ‡∏≤‡∏á OpenAI Client
openai_client = AsyncOpenAI(api_key=API_KEY, base_url=BASE_URL)

async def run_agent(user_query: str):
    print(f"üîå ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ MCP Server: {SERVER_URL}...")
    
    # ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö MCP Server
    async with sse_client(SERVER_URL) as (read, write):
        async with ClientSession(read, write) as session:
            await session.initialize()
            
            # 2. ‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ Tools ‡∏à‡∏≤‡∏Å MCP Server
            mcp_tools = await session.list_tools()
            
            # 3. ‡πÅ‡∏õ‡∏•‡∏á Tools ‡∏Ç‡∏≠‡∏á MCP ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô Format ‡∏ó‡∏µ‡πà OpenAI ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à
            openai_tools = []
            for tool in mcp_tools.tools:
                openai_tools.append({
                    "type": "function",
                    "function": {
                        "name": tool.name,
                        "description": tool.description,
                        "parameters": tool.inputSchema # MCP ‡πÉ‡∏ä‡πâ JSON Schema ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß ‡πÇ‡∏¢‡∏ô‡πÉ‡∏™‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢!
                    }
                })
            
            print(f"üõ†Ô∏è  AI ‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠: {[t['function']['name'] for t in openai_tools]}")

            # 4. ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Ñ‡∏∏‡∏¢‡∏Å‡∏±‡∏ö AI (‡∏™‡πà‡∏á System prompt + User query)
            messages = [
                {"role": "system", "content": "‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏†‡∏≤‡∏¢‡∏ô‡∏≠‡∏Å‡πÑ‡∏î‡πâ"},
                {"role": "user", "content": user_query}
            ]

            print(f"ü§ñ User: {user_query}")
            
            # ‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ OpenAI ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à (‡∏£‡∏≠‡∏ö‡πÅ‡∏£‡∏Å)
            response = await openai_client.chat.completions.create(
                model=MODEL_NAME,
                messages=messages,
                tools=openai_tools,
                tool_choice="auto" # ‡πÉ‡∏´‡πâ AI ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ Tool ‡πÑ‡∏´‡∏°
            )

            response_message = response.choices[0].message
            tool_calls = response_message.tool_calls

            # 5. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ AI ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ Tool ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà?
            if tool_calls:
                print(f"ü§î AI ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ Tool: {len(tool_calls)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
                
                # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡∏Ç‡∏≠‡∏á AI (‡∏ó‡∏µ‡πà‡∏°‡∏µ tool_calls) ‡∏•‡∏á‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ Context ‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á
                messages.append(response_message)

                for tool_call in tool_calls:
                    function_name = tool_call.function.name
                    function_args = json.loads(tool_call.function.arguments)
                    
                    print(f"üöÄ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏£‡∏±‡∏ô: {function_name} ‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡πà‡∏≤ {function_args}")
                    
                    # --- ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ MCP Tool ‡∏Ç‡∏≠‡∏á‡∏à‡∏£‡∏¥‡∏á‡∏ó‡∏µ‡πà Server ---
                    result = await session.call_tool(function_name, arguments=function_args)
                    tool_output = result.content[0].text
                    print(f"‚úÖ ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å Server: {tool_output}")

                    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏Ñ‡∏∏‡∏¢ (Role: tool)
                    messages.append({
                        "tool_call_id": tool_call.id,
                        "role": "tool",
                        "name": function_name,
                        "content": tool_output,
                    })

                # 6. ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏Å‡∏•‡∏±‡∏ö‡πÉ‡∏´‡πâ OpenAI ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
                final_response = await openai_client.chat.completions.create(
                    model=MODEL_NAME,
                    messages=messages
                )
                print(f"\nüì¢ AI ‡∏ï‡∏≠‡∏ö‡∏™‡∏£‡∏∏‡∏õ:\n{final_response.choices[0].message.content}")
            
            else:
                # ‡∏ñ‡πâ‡∏≤ AI ‡πÑ‡∏°‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏Å Tool ‡∏Å‡πá‡∏ï‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤
                print(f"\nüì¢ AI ‡∏ï‡∏≠‡∏ö:\n{response_message.content}")

if __name__ == "__main__":
    # ‡∏•‡∏≠‡∏á‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö
    # ‡πÄ‡∏ä‡πà‡∏ô "‡∏ö‡∏ß‡∏Å‡πÄ‡∏•‡∏Ç 50 ‡∏Å‡∏±‡∏ö 25 ‡πÉ‡∏´‡πâ‡∏´‡∏ô‡πà‡∏≠‡∏¢" ‡∏´‡∏£‡∏∑‡∏≠ "‡∏ä‡πà‡∏ß‡∏¢‡∏ó‡∏±‡∏Å‡∏ó‡∏≤‡∏¢‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ä‡∏≤‡∏¢‡∏´‡∏ô‡πà‡∏≠‡∏¢"
    query = "‡∏ä‡πà‡∏ß‡∏¢‡∏ö‡∏ß‡∏Å‡πÄ‡∏•‡∏Ç 1234 ‡∏Å‡∏±‡∏ö 5678 ‡πÉ‡∏´‡πâ‡∏´‡∏ô‡πà‡∏≠‡∏¢ ‡πÅ‡∏•‡πâ‡∏ß‡∏Å‡πá‡∏ó‡∏±‡∏Å‡∏ó‡∏≤‡∏¢‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏´‡∏ç‡∏¥‡∏á‡∏î‡πâ‡∏ß‡∏¢"
    asyncio.run(run_agent(query))